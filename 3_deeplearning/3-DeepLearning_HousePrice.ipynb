{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "totXFY9Bodlo"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lm2612/Tutorials/blob/main/3_deeplearning/3-DeepLearning_HousePrice.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q2ZRtPnodlq"
      },
      "source": [
        "# Deep learning: House price prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw3ZffZ7odlq"
      },
      "source": [
        "On Tuesday, we used linear regression to predict house prices of the [California house price dataset](https://www.kaggle.com/camnugent/california-housing-prices). Our dataset contains 200 observations for housing blocks in California obtained from the 1990 census. The dataset contains columns:\n",
        "\n",
        "1. `longitude`: A measure of how far west a house is; a higher value is farther west\n",
        "\n",
        "2. `latitude`: A measure of how far north a house is; a higher value is farther north\n",
        "\n",
        "3. `housing_median_age`: Median age of a house within a block; a lower number is a newer building\n",
        "\n",
        "4. `total_rooms`: Total number of rooms within a block\n",
        "\n",
        "5. `total_bedrooms`: Total number of bedrooms within a block\n",
        "\n",
        "6. `population`: Total number of people residing within a block\n",
        "\n",
        "7. `households`: Total number of households, a group of people residing within a home unit, for a block\n",
        "\n",
        "8. `median_income`: Median income for households within a block of houses (measured in tens of thousands of US Dollars)\n",
        "\n",
        "9. `median_house_value`: Median house value for households within a block (measured in US Dollars)\n",
        "\n",
        "10. `ocean_proximity`: Location of the house w.r.t ocean/sea\n",
        "\n",
        "Previously, we used intuition to guess what input variables would be suitable predictors. In this example, we are going to  use all the variables available and to predict `median_house_value`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTky19jdodlq"
      },
      "source": [
        "You must be on google colab for this tutorial - otherwise you will not be able to open the dataset. First, import the needed modules, we will be using `torch` for building neural networks. On Tuesday we used a smaller subset of the full dataset. Load the file `sample_data/california_housing_train.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UIv7u841odlr",
        "outputId": "f59d44e4-965b-47fd-e15e-2944cf2e5920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28785a41-8046-4a82-9d51-1e94069c6cf8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28785a41-8046-4a82-9d51-1e94069c6cf8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28785a41-8046-4a82-9d51-1e94069c6cf8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28785a41-8046-4a82-9d51-1e94069c6cf8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-621c82fe-f7a8-46c3-b2d4-5bc545de6f6a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-621c82fe-f7a8-46c3-b2d4-5bc545de6f6a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-621c82fe-f7a8-46c3-b2d4-5bc545de6f6a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17000,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.005166408426173,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 827,\n        \"samples\": [\n          -117.56,\n          -123.32,\n          -118.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1373397946570734,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 840,\n        \"samples\": [\n          38.44,\n          40.79,\n          32.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.586936981660335,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          23.0,\n          52.0,\n          47.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2179.947071452768,\n        \"min\": 2.0,\n        \"max\": 37937.0,\n        \"num_unique_values\": 5533,\n        \"samples\": [\n          3564.0,\n          6955.0,\n          5451.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.49945157986514,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1848,\n        \"samples\": [\n          729.0,\n          719.0,\n          2075.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1147.852959159525,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3683,\n        \"samples\": [\n          249.0,\n          1735.0,\n          235.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 384.52084085590013,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1740,\n        \"samples\": [\n          390.0,\n          1089.0,\n          1351.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.908156518379093,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 11175,\n        \"samples\": [\n          7.2655,\n          5.6293,\n          4.2262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115983.76438720913,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3694,\n        \"samples\": [\n          162300.0,\n          346800.0,\n          116700.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "df = pd.read_csv(\"sample_data/california_housing_train.csv\")\n",
        "print(len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFKGH_B5odlr"
      },
      "source": [
        "Notice the dataset is much larger than Tuesday! Clean up the data and split it into training and validation. Note, we don't need to set aside test data as we will use the test data in `sample_data/california_housing_test.csv`. Remember the data is ordered, you may want to shuffle it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the DataFrame\n",
        "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
        "\n",
        "# Split the data into training and validation sets (80/20 split)\n",
        "train_size = int(0.8 * len(df))\n",
        "train_df = df[:train_size]\n",
        "val_df = df[train_size:]\n",
        "\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")"
      ],
      "metadata": {
        "id": "c_2GzW75pj5C",
        "outputId": "cb083e69-47fe-42fb-c1d3-0fcb0aa96783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 13600\n",
            "Validation set size: 3400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV6pt-w_odlr"
      },
      "outputs": [],
      "source": [
        "# # Remove nans\n",
        "# df =\n",
        "\n",
        "# # Shuffle the data\n",
        "# from sklearn.utils import shuffle\n",
        "# df ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpZla8c0odlr"
      },
      "outputs": [],
      "source": [
        "# # Use 80% training, 20% validation\n",
        "# training = df.iloc[\n",
        "# validation = df.iloc["
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EoipNwXodls"
      },
      "source": [
        "Get your X and y variables. We will use all of the predictors for X and scale them to zero mean unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gFHfG43oodls",
        "outputId": "752b23f7-f024-4a2f-91f5-8cbc7e54804f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13600, 8), (13600, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "y = train_df[\"median_house_value\"].values.reshape(-1, 1)\n",
        "X = train_df[['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        "       'total_bedrooms', 'population', 'households', 'median_income']].values\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_mlDoshCodls"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Use StandardScaler to fit and transform your variables\n",
        "# Create a StandardScaler instance for features (X)\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data and transform X\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "# Create a StandardScaler instance for the target variable (y)\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data and transform y\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "'''\n",
        "1. Feature Scale Differences and Algorithm Performance:\n",
        "\n",
        "Many machine learning algorithms are sensitive to the scale of features. If features have vastly different ranges (e.g., one feature ranges from 0 to 1, while another ranges from 1000 to 10000), those with larger ranges can disproportionately influence the model's learning process.\n",
        "Algorithms like gradient descent, k-nearest neighbors, support vector machines, and linear regression can be significantly affected by unscaled data.\n",
        "For example, in distance-based algorithms like k-nearest neighbors, features with larger ranges will have a greater impact on the distance calculations, potentially leading to biased results.\n",
        "2. Improved Model Performance:\n",
        "\n",
        "Scaling helps to level the playing field for all features, allowing the model to learn relationships between them more effectively. This often leads to improved model accuracy and performance.\n",
        "By reducing the dominance of features with larger ranges, scaling helps prevent the model from being overly influenced by irrelevant or less important features.\n",
        "3. Faster Convergence:\n",
        "\n",
        "Scaling can significantly speed up the training process, particularly for algorithms like gradient descent. When features are on different scales, the optimization process can take longer to converge to a solution. Scaling helps to normalize the feature space, enabling the algorithm to find the optimal solution more efficiently.\n",
        "4. Comparability:\n",
        "\n",
        "Scaling makes it easier to compare and interpret the importance of different features. When features are on the same scale, their coefficients or feature importance scores become more meaningful and comparable.\n",
        "5. Algorithm Requirements:\n",
        "\n",
        "Some algorithms, like principal component analysis (PCA) and support vector machines (SVM), may require or benefit significantly from data scaling as part of their inherent workings.\n",
        "In summary:\n",
        "\n",
        "Scaling your data is generally a good practice in machine learning, especially when using algorithms that are sensitive to feature scales. It helps to improve model performance, speed up training, and make the results more interpretable. While there might be exceptions where scaling is not strictly necessary, it's often a safe and beneficial step to include in your preprocessing pipeline.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvXhyXdgodls"
      },
      "source": [
        "Create torch tensors ready for the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ul368xiBodls"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y = torch.tensor(y_scaled, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En8joTxsodls"
      },
      "source": [
        "## Build a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvtKeV78odls"
      },
      "source": [
        "Create a simple neural network. It can include as many or as few layers as you like. We will start simple with a 3-layer dense neural network, where we have an input layer, and 2 hidden layers with 16 nodes. For the input layer, we need to tell pytorch the number of input features (9). Then we can choose the number of hidden nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "myMlplwPodls"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(torch.nn.Module):\n",
        "    def __init__(self, n_features=8, n_targets=1):\n",
        "        super().__init__()\n",
        "        self.n_features = n_features\n",
        "        self.n_targets = n_targets\n",
        "\n",
        "        self.layer_input = torch.nn.Linear(self.n_features, 16)         # Input layer: n_features -> 16\n",
        "        self.layer_hidden1 = torch.nn.Linear(16, 16)                    # Hidden layer 1: 16 -> 16\n",
        "        self.layer_hidden2 = torch.nn.Linear(16, self.n_targets)        # Hidden layer 2: 16 -> n_targets\n",
        "\n",
        "        self.activation_function = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Input layer\n",
        "        output = self.layer_input(X)\n",
        "        output = self.activation_function(output)\n",
        "\n",
        "        # Hidden layer 1\n",
        "        output = self.layer_hidden1(output)\n",
        "        output = self.activation_function(output)\n",
        "\n",
        "        # Hidden layer 2\n",
        "        output = self.layer_hidden2(output)\n",
        "        # Notice we don't use the activation function here - why not? when would we use it?\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCuncMOfodlt"
      },
      "source": [
        "## Check our network on one batch\n",
        "Let's test our neural network on a small batch of data, before we start our training loop. Create an instance of SimpleNet and test it on a batch size of 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E8Zs70qhodlt",
        "outputId": "9a0cf6ba-d1fc-493a-af31-3ef3e3d0d264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1])\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of SimpleNet\n",
        "my_network = SimpleNet(n_features=8, n_targets=1)\n",
        "batch_size = 64\n",
        "\n",
        "# Get a batch of data\n",
        "X_batch = X[:batch_size]\n",
        "y_batch = y[:batch_size]\n",
        "\n",
        "# Test if we can call my_network without any errors\n",
        "pred_batch = my_network(X_batch)\n",
        "\n",
        "# Check the output is the correct size\n",
        "print(pred_batch.shape)\n",
        "assert(pred_batch.shape == y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LQ90g52odlt"
      },
      "source": [
        "## Set up loss function and optimisation algorithms\n",
        "\n",
        "Decide on a suitable loss function.\n",
        "\n",
        "We will use Mean Squared Error (MSE). It is always good to check you can properly call this on your first batch of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UqlaYtALodlt",
        "outputId": "87b22314-8079-437c-f2c3-cd075df33184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9050, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "loss_function = torch.nn.MSELoss()\n",
        "loss_function(pred_batch, y_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqUfFbVnodlt"
      },
      "source": [
        "Set up the optimiser and pass our network parameters to it. We will use the Adam optimiser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qwNuQ-jgodlt"
      },
      "outputs": [],
      "source": [
        "optimiser = torch.optim.Adam(params = my_network.parameters(), lr=0.01)\n",
        "\n",
        "'''\n",
        "This line is crucial for training our neural network. It sets up the optimization process that will help the network learn and improve its predictions. Here's a step-by-step explanation:\n",
        "\n",
        "optimiser =: This part is simply creating a variable named optimiser to store our chosen optimization algorithm. Think of it as a container for the optimization process.\n",
        "\n",
        "torch.optim.Adam: This is the specific optimization algorithm we're using, called \"Adam.\" It's a popular choice for training neural networks because it's generally efficient and effective.\n",
        "\n",
        "params = my_network.parameters(): This is where we tell the optimizer which values it should adjust during training. my_network.parameters() refers to all the adjustable parameters (weights and biases) within our neural network, my_network. These are the internal values that the optimizer will try to tweak to improve the network's performance.\n",
        "\n",
        "lr=0.01: \"lr\" stands for \"learning rate.\" It's a crucial parameter that controls how much the optimizer adjusts the network's parameters in each step of training. A learning rate of 0.01 means that the optimizer will make relatively small adjustments to the parameters during each update. Finding a good learning rate is often important for successful training.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q1lkuPGodlt"
      },
      "source": [
        "## Training loop\n",
        "We are ready to start our training loop. We could manually iterate through the data using indices, e.g., `X[0:64, :], y[0:64, :], ...`. But pytorch simplifies this for us with some useful functions, including mini-batching and shuffling - this will become essential when we move to large datasets. This is done in two steps, both of which are highly customisable.\n",
        "First, we create a `Dataset` which contains all of our data (you can also include any relevant pre-processing functions inside the Dataset). For regression, we provide our inputs and outputs.\n",
        "Then, we use a `DataLoader` that allows us to iterate through minibatches of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpCwmDBqodlt"
      },
      "outputs": [],
      "source": [
        "dataset = torch.utils.data.TensorDataset(X, y)\n",
        "dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                         shuffle=True,\n",
        "                                         batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rasn5lmkodlt"
      },
      "outputs": [],
      "source": [
        "# Check we can iterate through the dataloader\n",
        "X_batch, y_batch = next(iter(dataloader))\n",
        "X_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE1WzbBSodlv"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "\n",
        "for X_batch, y_batch in dataloader:\n",
        "    optimiser.zero_grad()\n",
        "    pred_batch = my_network(X_batch)\n",
        "    loss = loss_function(pred_batch, y_batch)\n",
        "    loss.backward()\n",
        "\n",
        "    # Update optimiser\n",
        "    optimiser.step()\n",
        "\n",
        "    # Add MSE losses to our list for plotting\n",
        "    losses.append(loss.item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsYz6mE4odlx"
      },
      "source": [
        "Plot the losses for this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtNqDb2Yodly"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s9oTvXFodlz"
      },
      "source": [
        "## Check validation dataset\n",
        "Predict using the validation dataset and compare to the true validation dataset. Check our loss function (MSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rObZ2TQModl2"
      },
      "outputs": [],
      "source": [
        "# Select your X_validation and y_validation variables.\n",
        "y_validation =\n",
        "X_validation =\n",
        "\n",
        "# Scale them and create them as torch tensors (as we did for training)\n",
        "\n",
        "X_validation_scaled =\n",
        "y_validation_scaled =\n",
        "\n",
        "X_validation = torch.tensor(\n",
        "y_validation = torch.tensor(\n",
        "\n",
        "# Create a torch dataset in the same way did before\n",
        "dataset_validation =\n",
        "\n",
        "# And finally, create a validation dataloader with a batch size of 64 in the same way we did before\n",
        "dataloader_validation ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JoP0I1Sodl5"
      },
      "outputs": [],
      "source": [
        "# Test the network on the validation dataset! Note, we need to put the network in \"evaluation\" mode first\n",
        "my_network.eval()       # Puts network into evaluation mode\n",
        "pred_validation =\n",
        "# Check the loss\n",
        "loss =\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfqhmxgsodl7"
      },
      "source": [
        "Plot the predicted against the truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GWaUvHvodl9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszXwtkiodl9"
      },
      "source": [
        "How does it compare to your linear regression models on Tuesday?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVB6XCBvodl9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfin4Jw9odl9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5UB5mA9odl9"
      },
      "source": [
        "## Train over multiple epochs\n",
        "\n",
        "Now you have gone through one full iteration of the data, train over multiple epochs and make sure you go through the validation dataset each epoch. Keep track of the training and validation losses averaged over each epoch separately and plot these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e4YdD__odl9"
      },
      "outputs": [],
      "source": [
        "training_losses = []\n",
        "validation_losses = []\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Set up training\n",
        "    my_network.train()\n",
        "    training_loss = 0\n",
        "\n",
        "    # TRAINING LOOP\n",
        "    # This will look the similar our previous single iteration\n",
        "    for ...\n",
        "\n",
        "    # Sum the training loss at each iteration and store the mean training loss at the end of the epoch\n",
        "    training_losses.append(training_loss)\n",
        "\n",
        "    # Set up validation\n",
        "    my_network.eval()\n",
        "    validation_loss = 0\n",
        "\n",
        "    # VALIDATION LOOP\n",
        "    # This will look similar to your training loop, but remember you do not need to do the optimise step\n",
        "    for ...\n",
        "\n",
        "    # Add MSE losses to our list for plotting\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    # After every 10 epochs print mean losses\n",
        "    if epoch%10 ==0:\n",
        "        print(f\"After epoch {epoch}: Training loss={training_loss:.2f}, validation loss={validation_loss:.2f}\")\n",
        "\n",
        "print(f\"At end of training: Training loss={training_loss:.2f}, validation loss={validation_loss:.2f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcRuQTRNodl9"
      },
      "source": [
        "Check the training and validation loss curves. How do they differ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fihJSxdodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D363LiqodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsyn6aXDodmB"
      },
      "source": [
        "## Overfitting\n",
        "Keep training your network and look for signs of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA-3goneodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reYdOViSodmB"
      },
      "source": [
        "## Bonus: Exploring different choices\n",
        "Play around with different versions of the network. For example, try:\n",
        "* More or fewer layers.\n",
        "* More of fewer hidden nodes.\n",
        "* Different choice of [activation functions](https://pytorch.org/docs/main/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
        "* Different choice of [loss functions](https://pytorch.org/docs/main/nn.html#loss-functions)\n",
        "* Different choice of [optimiser](https://pytorch.org/docs/main/optim.html#algorithms)\n",
        "\n",
        "Selecting these choices for your problem is an optimisation problem in itself. This is often called hyperparameter selection. There is no best approach - usually people would manually search through some different options until we have the best results. Finding quicker methods for \"hyperparameter optimisation\" is a research field in itself!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1eBZdmOodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGaYINcodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eptRh4yodmB"
      },
      "source": [
        "### More layers\n",
        "Add one layer with 32 hidden nodes and see if it you get a better performance on the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsvPbkbLodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVwCTlb8odmB"
      },
      "source": [
        "## Bonus: Other network parameters\n",
        "Explore the following options:\n",
        "* add BatchNorm\n",
        "* replace the ReLU activation function with the Sigmoid activation function\n",
        "* remove a hidden layer\n",
        "* try a different optimisation method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm86UzrOodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej8COi6nodmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqSofP7DodmB"
      },
      "source": [
        "## Testing\n",
        "Select your best network and apply it to the test data and calculate the RMSE. Don't forget your outputs are scaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6aqq9b8odmB"
      },
      "outputs": [],
      "source": [
        "# Open test data\n",
        "testing = pd.read_csv(\"sample_data/california_housing_test.csv\")\n",
        "testing.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmLrVJ80odmC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHpFZmD7odmC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJG0oM3eodmC"
      },
      "source": [
        "## Compare to Linear Regression\n",
        "Compare your code the linear regression results you got on Tuesday. Note you will need to re-run your linear regression on this new test dataset. You may also want to re-train on this larger training dataset for a fair comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyvqrgVoodmC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq1qrlsrodmC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D39ZpLIRodmC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}